{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf9060-0ea4-4ba2-a015-2e53dc467236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install \"sagemaker>=2.99.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf88fd1-bc05-47c9-bd0b-a5dfae3cb75d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sagemaker_session.boto_region_name\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "pipeline_session = PipelineSession()\n",
    "model_package_group_name = f\"AbaloneModelPackageGroupName\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5825d8-47a2-4141-94f5-d3f97cb2c3c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7d6a3a-aabd-48d8-a7cf-25f63c449011",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_path = 'data/abalone-dataset.csv'\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(f'sagemaker-sample-files').download_file(\"datasets/tabular/uci_abalone/abalone.csv\", local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da15bd3d-5721-4718-873e-e27dc9f3e0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_uri = f\"s3://{default_bucket}/abalone\"\n",
    "\n",
    "input_data_uri = sagemaker.s3.S3Uploader.upload(local_path = local_path, desired_s3_uri = base_uri)\n",
    "input_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81acd1a2-4bc7-409d-bb9a-ff1c4f464197",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_path = \"data/abalone-dataset-batch\"\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3.Bucket(f\"sagemaker-servicecatalog-seedcode-{region}\").download_file(\n",
    "    \"dataset/abalone-dataset-batch\", local_path\n",
    ")\n",
    "\n",
    "base_uri = f\"s3://{default_bucket}/abalone\"\n",
    "batch_data_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=local_path,\n",
    "    desired_s3_uri=base_uri,\n",
    ")\n",
    "print(batch_data_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbad938a-87ad-46fe-9143-e361b185fbc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat)\n",
    "\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\")\n",
    "model_approval_status = ParameterString(name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\")\n",
    "input_data = ParameterString(name=\"InputData\", default_value = input_data_uri)\n",
    "batch_data = ParameterString(name=\"BatchData\", default_value = batch_data_uri)\n",
    "mse_threshold = ParameterFloat(name=\"MseThreshold\", default_value=6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d7e217-b437-48f0-b2da-1970abad0490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0941ae3-4d37-45f1-8a4b-002d8e8d3b98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile code/preprocessing.py\n",
    "import argparse\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "# Since we get a headerless CSV file, we specify the column names here.\n",
    "feature_columns_names = [\n",
    "    \"sex\",\n",
    "    \"length\",\n",
    "    \"diameter\",\n",
    "    \"height\",\n",
    "    \"whole_weight\",\n",
    "    \"shucked_weight\",\n",
    "    \"viscera_weight\",\n",
    "    \"shell_weight\",\n",
    "]\n",
    "label_column = \"rings\"\n",
    "\n",
    "feature_columns_dtype = {\n",
    "    \"sex\": str,\n",
    "    \"length\": np.float64,\n",
    "    \"diameter\": np.float64,\n",
    "    \"height\": np.float64,\n",
    "    \"whole_weight\": np.float64,\n",
    "    \"shucked_weight\": np.float64,\n",
    "    \"viscera_weight\": np.float64,\n",
    "    \"shell_weight\": np.float64,\n",
    "}\n",
    "label_column_dtype = {\"rings\": np.float64}\n",
    "\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"/opt/ml/processing\"\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        f\"{base_dir}/input/abalone-dataset.csv\",\n",
    "        header=None,\n",
    "        names=feature_columns_names + [label_column],\n",
    "        dtype=merge_two_dicts(feature_columns_dtype, label_column_dtype),\n",
    "    )\n",
    "    numeric_features = list(feature_columns_names)\n",
    "    numeric_features.remove(\"sex\")\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    "    )\n",
    "\n",
    "    categorical_features = [\"sex\"]\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    y = df.pop(\"rings\")\n",
    "    X_pre = preprocess.fit_transform(df)\n",
    "    y_pre = y.to_numpy().reshape(len(y), 1)\n",
    "\n",
    "    X = np.concatenate((y_pre, X_pre), axis=1)\n",
    "\n",
    "    np.random.shuffle(X)\n",
    "    train, validation, test = np.split(X, [int(0.7 * len(X)), int(0.85 * len(X))])\n",
    "\n",
    "    pd.DataFrame(train).to_csv(f\"{base_dir}/train/train.csv\", header=False, index=False)\n",
    "    pd.DataFrame(validation).to_csv(\n",
    "        f\"{base_dir}/validation/validation.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(test).to_csv(f\"{base_dir}/test/test.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab03f16-5cba-44ef-992c-19aa4ccaee10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
